---
layout: post
title: Discrete Emotion Elicitation under Multiple Contexts with EEG Recordings
subtitle: (DEEMCER)
cover-img: /assets/img/exper.jpg
thumbnail-img: /assets/img/exper.jpg
share-img: /assets/img/exper.jpg
tags: [emotion decoding,EEG dataset]
author: Xu Xin
---

To prepare data for extracting cross-contextual commonalities in EEG-based emotional representations, we conducted experiments involving emotional elicitation across different contexts to build a comprehensive dataset. We have successfully completed EEG data collection from over thirty participants. This work is still ongoing.

Although existing research has demonstrated that various contexts can effectively induce emotions, experiments specifically designed for cross-contextual tasks have received less attention. We devised a novel experimental paradigm, as illustrated below:

![Paradigm of the experiment](https://github.com/xuxin11111/xuxin11111.github.io/blob/master/assets/img/paradigm.png?raw=true)


The experiment consists of two types: video stimuli and imagination under  audio guidence, encompassing seven blocks. Each block contains three consecutive imagination trials followed by three consecutive video trials, with the sequence of imagination and video stimuli randomized within each block. Although the content within each block is randomly selected, it is consistent in valence.

The materials used for elicitation have been extensively rated online to validate their effectiveness. During the experiments, we obtained consent from participants and collected their EEG signals and peripheral physiological data (primarily photoplethysmogram and skin conductance). We have preprocessed, validated, and analyzed the experimental data. Results including participants' behavioral data, EEG topographic maps, and baseline classifications all confirm the effectiveness of the emotional elicitation.

Our dataset lays the groundwork for cross-contextual data research. Advanced techniques such as deep learning models and source localization can be applied to our dataset for further analysis.
